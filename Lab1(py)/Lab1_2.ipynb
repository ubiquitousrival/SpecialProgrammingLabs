{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebbab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Імпорт необхідних бібліотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# Налаштування відображення для зручності\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e44a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Початок читання файлу: household_power_consumption.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_23972\\907263137.py:8: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_23972\\907263137.py:8: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет успішно завантажено.\n",
      "Форма датасету: (2075259, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_23972\\907263137.py:8: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Шлях до файлу. Змініть, якщо файл знаходиться в іншій директорії.\n",
    "file_path = 'household_power_consumption.txt'\n",
    "\n",
    "try:\n",
    "    # Читання датасету\n",
    "    # Використовуємо sep=';' та '?' як значення, що відсутні (na_values)\n",
    "    print(f\"Початок читання файлу: {file_path}\")\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=';',\n",
    "        parse_dates={'DateTime': ['Date', 'Time']},\n",
    "        infer_datetime_format=True,\n",
    "        na_values=['?'],\n",
    "        low_memory=False\n",
    "    )\n",
    "    print(\"Датасет успішно завантажено.\")\n",
    "    print(f\"Форма датасету: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Помилка: Файл '{file_path}' не знайдено.\")\n",
    "    print(\"Будь ласка, завантажте 'household_power_consumption.txt' у поточну директорію або змініть 'file_path'.\")\n",
    "    df = pd.DataFrame() # Створюємо порожній DataFrame для запобігання помилок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fead873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Початок Data Cleaning...\n",
      "\n",
      "Кількість NaN до очищення:\n",
      "DateTime                     0\n",
      "Global_active_power      25979\n",
      "Global_reactive_power    25979\n",
      "Voltage                  25979\n",
      "Global_intensity         25979\n",
      "Sub_metering_1           25979\n",
      "Sub_metering_2           25979\n",
      "Sub_metering_3           25979\n",
      "dtype: int64\n",
      "\n",
      "Кількість NaN після очищення:\n",
      "DateTime                 0\n",
      "Global_active_power      0\n",
      "Global_reactive_power    0\n",
      "Voltage                  0\n",
      "Global_intensity         0\n",
      "Sub_metering_1           0\n",
      "Sub_metering_2           0\n",
      "Sub_metering_3           0\n",
      "dtype: int64\n",
      "Data Cleaning завершено. Датафрейм готовий до аналізу.\n"
     ]
    }
   ],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"Початок Data Cleaning...\")\n",
    "    \n",
    "    # Виводимо кількість пропущених значень до очищення\n",
    "    print(\"\\nКількість NaN до очищення:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Завдання вимагає обробити пропущені дані.\n",
    "    # Оскільки це часовий ряд і велика кількість даних, а пропущені значення\n",
    "    # складають лише 1.25% від загальної кількості, найпоширенішими та\n",
    "    # ефективними методами є:\n",
    "    # 1. Видалення рядків з NaN (якщо їх мало).\n",
    "    # 2. Заміна середнім/медіаною/попереднім значенням.\n",
    "    \n",
    "    # Використаємо простий метод: заповнення NaN медіаною для числових колонок.\n",
    "    # Це допомагає зберегти розмір вибірки і менш чутливе до викидів, ніж середнє.\n",
    "    \n",
    "    # Конвертуємо всі колонки, крім першої ('DateTime'), у float,\n",
    "    # оскільки read_csv міг інтерпретувати їх як object через наявність '?'\n",
    "    cols_to_convert = df.columns.drop('DateTime')\n",
    "    for col in cols_to_convert:\n",
    "        # Використовуємо .loc для уникнення SettingWithCopyWarning\n",
    "        df.loc[:, col] = pd.to_numeric(df.loc[:, col], errors='coerce')\n",
    "        \n",
    "    # Заповнення NaN медіаною\n",
    "    median_values = df.median(numeric_only=True)\n",
    "    df_cleaned = df.fillna(median_values)\n",
    "    \n",
    "    # Виводимо кількість пропущених значень після очищення\n",
    "    print(\"\\nКількість NaN після очищення:\")\n",
    "    print(df_cleaned.isnull().sum())\n",
    "    \n",
    "    # Встановлюємо 'DateTime' як індекс для зручності роботи з часовими рядами\n",
    "    df_cleaned.set_index('DateTime', inplace=True)\n",
    "    \n",
    "    print(\"Data Cleaning завершено. Датафрейм готовий до аналізу.\")\n",
    "else:\n",
    "    print(\"Неможливо виконати Data Cleaning, оскільки датафрейм порожній або не завантажений.\")\n",
    "    df_cleaned = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc91a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Час виконання (Потужність > 5 кВт): 0.008501 сек.\n",
      "   Розмір вибірки 1: (17547, 7)\n",
      "2. Час виконання (Струм 19-20 А, S2 > S3): 0.008257 сек.\n",
      "   Розмір вибірки 2: (2509, 7)\n"
     ]
    }
   ],
   "source": [
    "def select_high_active_power(data, threshold=5):\n",
    "    \"\"\"Обирає записи, де Global_active_power перевищує поріг (кВт).\"\"\"\n",
    "    return data[data['Global_active_power'] > threshold]\n",
    "\n",
    "def select_current_and_submetering(data, current_min=19, current_max=20):\n",
    "    \"\"\"\n",
    "    Обирає записи за силою струму (19-20 А) та умовою:\n",
    "    Sub_metering_2 (Пральна машина, Холодильник) > Sub_metering_3 (Бойлер, Кондиціонер).\n",
    "    \"\"\"\n",
    "    # Фільтрація за силою струму\n",
    "    current_filter = (data['Global_intensity'] >= current_min) & \\\n",
    "                     (data['Global_intensity'] <= current_max)\n",
    "    \n",
    "    df_filtered_current = data[current_filter].copy()\n",
    "    \n",
    "    # Фільтрація за споживанням (група 2 > група 3)\n",
    "    consumption_filter = df_filtered_current['Sub_metering_2'] > df_filtered_current['Sub_metering_3']\n",
    "    \n",
    "    return df_filtered_current[consumption_filter]\n",
    "\n",
    "if not df_cleaned.empty:\n",
    "    # 1. Вибірка: Загальна активна потужність > 5 кВт\n",
    "    time_high_power = timeit.timeit(\n",
    "        lambda: select_high_active_power(df_cleaned, 5),\n",
    "        number=1\n",
    "    )\n",
    "    df_high_power = select_high_active_power(df_cleaned, 5)\n",
    "    print(f\"1. Час виконання (Потужність > 5 кВт): {time_high_power:.6f} сек.\")\n",
    "    print(f\"   Розмір вибірки 1: {df_high_power.shape}\")\n",
    "    \n",
    "    # 2. Вибірка: 19 A <= Сила струму <= 20 A та Sub_metering_2 > Sub_metering_3\n",
    "    time_current_submetering = timeit.timeit(\n",
    "        lambda: select_current_and_submetering(df_cleaned),\n",
    "        number=1\n",
    "    )\n",
    "    df_current_submetering = select_current_and_submetering(df_cleaned)\n",
    "    print(f\"2. Час виконання (Струм 19-20 А, S2 > S3): {time_current_submetering:.6f} сек.\")\n",
    "    print(f\"   Розмір вибірки 2: {df_current_submetering.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b51df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Час виконання (Випадкова вибірка 500k): 0.108933 сек.\n",
      "   Розмір вибірки 3: (500000, 7)\n",
      "   Середні Sub_metering: S1=1.109, S2=1.284, S3=6.397\n",
      "4. Час виконання (Складна вибірка по часу): 0.044558 сек.\n",
      "   Розмір вибірки 4: (310, 7)\n"
     ]
    }
   ],
   "source": [
    "def select_random_sample_and_calculate_mean(data, n_samples=500000):\n",
    "    \"\"\"\n",
    "    Обирає n випадкових записів без повторів та обчислює середні \n",
    "    для Sub_metering 1, 2, 3.\n",
    "    \"\"\"\n",
    "    # Випадкова вибірка без повторів\n",
    "    df_sample = data.sample(n=n_samples, replace=False, random_state=42)\n",
    "    \n",
    "    # Обчислення середніх\n",
    "    mean_sub1 = df_sample['Sub_metering_1'].mean()\n",
    "    mean_sub2 = df_sample['Sub_metering_2'].mean()\n",
    "    mean_sub3 = df_sample['Sub_metering_3'].mean()\n",
    "    \n",
    "    return df_sample, (mean_sub1, mean_sub2, mean_sub3)\n",
    "\n",
    "def select_complex_time_based(data, power_threshold=6):\n",
    "    \"\"\"\n",
    "    Обирає записи після 18:00 з потужністю > 6 кВт, \n",
    "    де Sub_metering_2 є найбільшою,\n",
    "    а потім застосовує складну індексацію.\n",
    "    \"\"\"\n",
    "    # 1. Фільтрація за часом (після 18-00) та потужністю (> 6 кВт)\n",
    "    # Зверніть увагу: індекс вже є DateTimeIndex\n",
    "    time_power_filter = (data.index.hour >= 18) & \\\n",
    "                        (data['Global_active_power'] > power_threshold)\n",
    "    df_filtered_time = data[time_power_filter].copy()\n",
    "    \n",
    "    # 2. Визначення, де Sub_metering_2 є найбільшою\n",
    "    # Використовуємо .values для ефективнішого порівняння\n",
    "    s2_max_filter = (df_filtered_time['Sub_metering_2'].values > df_filtered_time['Sub_metering_1'].values) & \\\n",
    "                    (df_filtered_time['Sub_metering_2'].values > df_filtered_time['Sub_metering_3'].values)\n",
    "    df_s2_max = df_filtered_time[s2_max_filter]\n",
    "    \n",
    "    # 3. Складна індексація\n",
    "    n_rows = len(df_s2_max)\n",
    "    half_point = n_rows // 2\n",
    "    \n",
    "    # Перша половина: кожен третій результат\n",
    "    first_half = df_s2_max.iloc[:half_point:3]\n",
    "    \n",
    "    # Друга половина: кожен четвертий результат\n",
    "    second_half = df_s2_max.iloc[half_point::4]\n",
    "    \n",
    "    # Об'єднання результатів\n",
    "    final_selection = pd.concat([first_half, second_half])\n",
    "    \n",
    "    return final_selection\n",
    "\n",
    "if not df_cleaned.empty:\n",
    "    # 3. Вибірка: Випадкові 500000 записів та обчислення середніх\n",
    "    time_random_sample = timeit.timeit(\n",
    "        lambda: select_random_sample_and_calculate_mean(df_cleaned),\n",
    "        number=1\n",
    "    )\n",
    "    df_random_sample, means = select_random_sample_and_calculate_mean(df_cleaned)\n",
    "    print(f\"3. Час виконання (Випадкова вибірка 500k): {time_random_sample:.6f} сек.\")\n",
    "    print(f\"   Розмір вибірки 3: {df_random_sample.shape}\")\n",
    "    print(f\"   Середні Sub_metering: S1={means[0]:.3f}, S2={means[1]:.3f}, S3={means[2]:.3f}\")\n",
    "    \n",
    "    # 4. Вибірка: Складна часова фільтрація та індексація\n",
    "    time_complex_selection = timeit.timeit(\n",
    "        lambda: select_complex_time_based(df_cleaned),\n",
    "        number=1\n",
    "    )\n",
    "    df_complex_selection = select_complex_time_based(df_cleaned)\n",
    "    print(f\"4. Час виконання (Складна вибірка по часу): {time_complex_selection:.6f} сек.\")\n",
    "    print(f\"   Розмір вибірки 4: {df_complex_selection.shape}\")\n",
    "    \n",
    "    # Вибираємо випадкову вибірку для подальших кроків (нормування, кореляція, OHE)\n",
    "    df_for_analysis = df_random_sample.copy()\n",
    "else:\n",
    "    print(\"Пропуск операцій, оскільки датафрейм порожній.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78c81e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Час виконання (Нормування Min-Max): 0.042353 сек.\n",
      "Час виконання (Стандартизація Z-score): 0.067945 сек.\n",
      "\n",
      "Перші 5 рядків нормованого/стандартизованого датасету:\n",
      "                     Global_active_power  Global_active_power_Normalized  Global_active_power_Standardized\n",
      "DateTime                                                                                                  \n",
      "2010-07-07 18:10:00                0.256                        0.016837                         -0.789222\n",
      "2007-05-14 06:50:00                0.466                        0.036701                         -0.589539\n",
      "2007-09-26 18:10:00                0.758                        0.064321                         -0.311885\n",
      "2007-06-19 07:30:00                1.290                        0.114642                          0.193979\n",
      "2010-05-10 04:43:00                0.428                        0.033106                         -0.625672\n"
     ]
    }
   ],
   "source": [
    "if not df_for_analysis.empty:\n",
    "    # Вибираємо числові колонки для нормування/стандартизації\n",
    "    numeric_cols = df_for_analysis.columns.tolist()\n",
    "    \n",
    "    # Створюємо копію для операцій\n",
    "    df_norm_std = df_for_analysis.copy()\n",
    "\n",
    "    # --- 1. Нормування (Min-Max Scaling) ---\n",
    "    def min_max_normalize(series):\n",
    "        return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "    time_normalize = timeit.timeit(\n",
    "        lambda: df_norm_std[numeric_cols].apply(min_max_normalize, axis=0),\n",
    "        number=1\n",
    "    )\n",
    "    df_normalized = df_norm_std[numeric_cols].apply(min_max_normalize, axis=0)\n",
    "    df_normalized.columns = [col + '_Normalized' for col in numeric_cols]\n",
    "    \n",
    "    print(f\"Час виконання (Нормування Min-Max): {time_normalize:.6f} сек.\")\n",
    "    \n",
    "    # --- 2. Стандартизація (Z-score Scaling) ---\n",
    "    def z_score_standardize(series):\n",
    "        return (series - series.mean()) / series.std()\n",
    "\n",
    "    time_standardize = timeit.timeit(\n",
    "        lambda: df_norm_std[numeric_cols].apply(z_score_standardize, axis=0),\n",
    "        number=1\n",
    "    )\n",
    "    df_standardized = df_norm_std[numeric_cols].apply(z_score_standardize, axis=0)\n",
    "    df_standardized.columns = [col + '_Standardized' for col in numeric_cols]\n",
    "    \n",
    "    print(f\"Час виконання (Стандартизація Z-score): {time_standardize:.6f} сек.\")\n",
    "    \n",
    "    # Об'єднання в один DataFrame для перевірки\n",
    "    df_processed = pd.concat([df_norm_std, df_normalized, df_standardized], axis=1)\n",
    "    \n",
    "    print(\"\\nПерші 5 рядків нормованого/стандартизованого датасету:\")\n",
    "    print(df_processed[['Global_active_power', 'Global_active_power_Normalized', 'Global_active_power_Standardized']].head())\n",
    "else:\n",
    "    print(\"Пропуск нормування та стандартизації, оскільки датафрейм для аналізу порожній.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d86e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обчислення кореляції між 'Global_active_power' та 'Global_reactive_power':\n",
      "   Коефіцієнт Пірсона: 0.247746 (Час: 0.009096 сек.)\n",
      "   Коефіцієнт Спірмена: 0.265113 (Час: 0.089634 сек.)\n"
     ]
    }
   ],
   "source": [
    "if not df_for_analysis.empty:\n",
    "    attr1 = 'Global_active_power'\n",
    "    attr2 = 'Global_reactive_power'\n",
    "\n",
    "    print(f\"Обчислення кореляції між '{attr1}' та '{attr2}':\")\n",
    "\n",
    "    # --- 1. Коефіцієнт Пірсона (Pearson) ---\n",
    "    time_pearson = timeit.timeit(\n",
    "        lambda: df_for_analysis[[attr1, attr2]].corr(method='pearson').iloc[0, 1],\n",
    "        number=1\n",
    "    )\n",
    "    pearson_corr = df_for_analysis[[attr1, attr2]].corr(method='pearson').iloc[0, 1]\n",
    "    \n",
    "    print(f\"   Коефіцієнт Пірсона: {pearson_corr:.6f} (Час: {time_pearson:.6f} сек.)\")\n",
    "\n",
    "    # --- 2. Коефіцієнт Спірмена (Spearman) ---\n",
    "    time_spearman = timeit.timeit(\n",
    "        lambda: df_for_analysis[[attr1, attr2]].corr(method='spearman').iloc[0, 1],\n",
    "        number=1\n",
    "    )\n",
    "    spearman_corr = df_for_analysis[[attr1, attr2]].corr(method='spearman').iloc[0, 1]\n",
    "    \n",
    "    print(f\"   Коефіцієнт Спірмена: {spearman_corr:.6f} (Час: {time_spearman:.6f} сек.)\")\n",
    "else:\n",
    "    print(\"Пропуск обчислення кореляцій, оскільки датафрейм для аналізу порожній.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722bf9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Створено категоріальний атрибут 'Time_of_Day'.\n",
      "Time_of_Day\n",
      "Morning    145810\n",
      "Night      145751\n",
      "Day        125050\n",
      "Evening     83389\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Час виконання (One Hot Encoding): 0.046492 сек.\n",
      "\n",
      "Перші 5 рядків датафрейму після OHE:\n",
      "                     Global_active_power  Time_of_Day_Day  Time_of_Day_Evening  Time_of_Day_Morning  Time_of_Day_Night\n",
      "DateTime                                                                                                              \n",
      "2010-07-07 18:10:00                0.256            False                 True                False              False\n",
      "2007-05-14 06:50:00                0.466            False                False                 True              False\n",
      "2007-09-26 18:10:00                0.758            False                 True                False              False\n",
      "2007-06-19 07:30:00                1.290            False                False                 True              False\n",
      "2010-05-10 04:43:00                0.428            False                False                False               True\n",
      "\n",
      "Кількість колонок після OHE: 11\n"
     ]
    }
   ],
   "source": [
    "if not df_for_analysis.empty:\n",
    "    df_ohe = df_for_analysis.copy()\n",
    "    \n",
    "    # --- 1. Створення категоріального атрибута (Година доби) ---\n",
    "    def get_time_of_day(hour):\n",
    "        if 5 <= hour < 12:\n",
    "            return 'Morning'\n",
    "        elif 12 <= hour < 18:\n",
    "            return 'Day'\n",
    "        elif 18 <= hour < 22:\n",
    "            return 'Evening'\n",
    "        else:\n",
    "            return 'Night'\n",
    "\n",
    "    # Створюємо нову колонку 'Time_of_Day'\n",
    "    df_ohe['Time_of_Day'] = df_ohe.index.hour.map(get_time_of_day)\n",
    "    \n",
    "    print(\"Створено категоріальний атрибут 'Time_of_Day'.\")\n",
    "    print(df_ohe['Time_of_Day'].value_counts())\n",
    "    \n",
    "    # --- 2. Виконання One Hot Encoding (OHE) ---\n",
    "    category_col = 'Time_of_Day'\n",
    "    \n",
    "    # Використовуємо pd.get_dummies, яка за замовчуванням видаляє оригінальну колонку\n",
    "    time_ohe = timeit.timeit(\n",
    "        lambda: pd.get_dummies(df_ohe, columns=[category_col], prefix=category_col),\n",
    "        number=1\n",
    "    )\n",
    "    df_ohe_encoded = pd.get_dummies(df_ohe, columns=[category_col], prefix=category_col)\n",
    "    \n",
    "    print(f\"\\nЧас виконання (One Hot Encoding): {time_ohe:.6f} сек.\")\n",
    "    \n",
    "    print(\"\\nПерші 5 рядків датафрейму після OHE:\")\n",
    "    # Виводимо тільки НОВІ, закодовані колонки\n",
    "    # (оригінальна колонка 'Time_of_Day' була видалена, тому її не можна вивести)\n",
    "    ohe_cols = [col for col in df_ohe_encoded.columns if col.startswith(f'{category_col}_')]\n",
    "    \n",
    "    # Виводимо частину оригінального датафрейму (для контексту) та нові колонки OHE\n",
    "    cols_to_show = ['Global_active_power'] + ohe_cols\n",
    "    print(df_ohe_encoded[cols_to_show].head())\n",
    "    \n",
    "    print(f\"\\nКількість колонок після OHE: {df_ohe_encoded.shape[1]}\")\n",
    "else:\n",
    "    print(\"Пропуск One Hot Encoding, оскільки датафрейм для аналізу порожній.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvlab1)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
